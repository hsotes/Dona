# Cap√≠tulo 24: Arquitecturas de Semantic Search

---

## La Arquitectura Vanilla: Bi-Encoder

> "La arquitectura que viste hasta ahora se llama **bi-encoder**."

### C√≥mo funciona:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                         ‚îÇ
‚îÇ   PRE-PROCESO (una vez):                               ‚îÇ
‚îÇ   Documento ‚Üí Embedding Model ‚Üí 1 vector               ‚îÇ
‚îÇ   (para cada documento en la KB)                       ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   EN CADA B√öSQUEDA:                                    ‚îÇ
‚îÇ   Prompt ‚Üí Embedding Model ‚Üí 1 vector                  ‚îÇ
‚îÇ   ANN busca vectores cercanos                          ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Por qu√© "bi-encoder":

```
Documentos y prompt se embeben SEPARADAMENTE.

Esto es importante porque:
‚îú‚îÄ‚îÄ Documentos pueden embeberse POR ADELANTADO
‚îú‚îÄ‚îÄ Solo el prompt se embebe despu√©s de recibirlo
‚îî‚îÄ‚îÄ B√∫squeda MUY R√ÅPIDA
```

### Trade-off:

```
‚úÖ Muy r√°pido
‚úÖ Escala bien
‚ùå Calidad de resultados "buena" pero no √≥ptima
```

---

## Cross-Encoder: Mejor Calidad, Peor Velocidad

### La idea:

```
En lugar de embeber documento y prompt por separado,
CONCATENAR ambos y pasarlos JUNTOS por el modelo.
```

### C√≥mo funciona:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                         ‚îÇ
‚îÇ   Para CADA documento:                                 ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   [PROMPT] + [DOCUMENTO] ‚Üí Cross-Encoder ‚Üí Score (0-1)‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   El score es la PROBABILIDAD de match                 ‚îÇ
‚îÇ   entre el prompt y ese documento.                     ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Ejemplo:

```
Prompt: "Great places to eat in New York"

Documento 1: "NYC has amazing cuisine options..."
[Prompt + Doc1] ‚Üí Cross-Encoder ‚Üí 0.70 (70% match)

Documento 2: "The weather in Seattle is rainy..."
[Prompt + Doc2] ‚Üí Cross-Encoder ‚Üí 0.05 (5% match)

Documento 3: "Central Park is beautiful..."
[Prompt + Doc3] ‚Üí Cross-Encoder ‚Üí 0.30 (30% match)
```

### Por qu√© es mejor:

```
Al tener AMBOS textos en el input:
‚îú‚îÄ‚îÄ El modelo entiende interacciones CONTEXTUALES profundas
‚îú‚îÄ‚îÄ Entre el prompt y el documento
‚îî‚îÄ‚îÄ Que un bi-encoder podr√≠a perder

Ejemplo:
Prompt: "eat in New York"
Doc: "NYC cuisine" 

Bi-encoder: Embebe cada uno por separado
            Puede no captar que "NYC" = "New York"
            
Cross-encoder: Ve ambos juntos
               Entiende la conexi√≥n contextual
```

---

### El Problema GRAVE del Cross-Encoder

```
‚ùå ESCALA TERRIBLEMENTE

Para CADA prompt:
‚îú‚îÄ‚îÄ Necesit√°s correr CADA documento por el cross-encoder
‚îú‚îÄ‚îÄ Si ten√©s 1 mill√≥n de documentos = 1 mill√≥n de pasadas
‚îú‚îÄ‚îÄ Si ten√©s 1 bill√≥n = 1 bill√≥n de pasadas

Y NO pod√©s pre-procesar nada porque:
‚îú‚îÄ‚îÄ El cross-encoder necesita [prompt + documento]
‚îú‚îÄ‚îÄ No ten√©s el prompt hasta que el usuario lo env√≠a
‚îî‚îÄ‚îÄ Todo el c√≥mputo es EN TIEMPO DE B√öSQUEDA

Resultado: Demasiado lento para usar como b√∫squeda principal
```

---

## ColBERT: El Balance

### ColBERT = Contextualized Late Interaction over BERT

### La idea:

```
‚îú‚îÄ‚îÄ Generar vectores por adelantado (como bi-encoder)
‚îú‚îÄ‚îÄ Pero capturar interacciones profundas (como cross-encoder)
‚îî‚îÄ‚îÄ ¬øC√≥mo? Un vector por CADA TOKEN
```

### C√≥mo funciona:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                         ‚îÇ
‚îÇ   PRE-PROCESO:                                         ‚îÇ
‚îÇ   Documento (1000 tokens) ‚Üí 1000 vectores              ‚îÇ
‚îÇ   (un vector por cada token)                           ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   EN B√öSQUEDA:                                         ‚îÇ
‚îÇ   Prompt (10 tokens) ‚Üí 10 vectores                     ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   SCORING:                                             ‚îÇ
‚îÇ   Cada token del prompt busca su token                 ‚îÇ
‚îÇ   M√ÅS SIMILAR en el documento.                         ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Ejemplo de Scoring en ColBERT

```
Prompt: "Great places to eat in New York"
        [vec1][vec2][vec3][vec4][vec5][vec6]

Documento: "NYC has amazing cuisine options in the city"
           [d1] [d2] [d3]   [d4]    [d5]  [d6][d7][d8]

GRID DE SIMILITUDES:
(cada prompt token vs cada doc token)

         d1    d2    d3     d4      d5     d6   d7   d8
        NYC   has  amazing cuisine options  in  the city
Great   0.1   0.1   0.3    0.2     0.1    0.1  0.1  0.1
places  0.1   0.1   0.1    0.2     0.4    0.1  0.1  0.3
to      0.1   0.2   0.1    0.1     0.1    0.3  0.2  0.1
eat     0.2   0.1   0.2    0.8‚Üê    0.3    0.1  0.1  0.1
in      0.2   0.1   0.1    0.1     0.1    0.9‚Üê 0.1  0.2
New     0.7‚Üê  0.1   0.1    0.1     0.1    0.1  0.1  0.3
York    0.8‚Üê  0.1   0.1    0.1     0.1    0.1  0.1  0.4‚Üê

‚Üê = m√°ximo por fila

MAX-SIM SCORE:
"eat" ‚Üí m√°ximo con "cuisine" (0.8)
"in" ‚Üí m√°ximo con "in" (0.9)
"New" ‚Üí m√°ximo con "NYC" (0.7)
"York" ‚Üí m√°ximo con "NYC" (0.8) o "city" (0.4)

Score total = suma de m√°ximos
```

### Por qu√© funciona:

```
‚úÖ "New York" en el prompt matchea con "NYC" en el doc
   (porque los tokens se comparan directamente)

‚úÖ "eat" matchea con "cuisine"
   (relaci√≥n sem√°ntica capturada)

‚úÖ Mucho m√°s rico que un solo vector por documento
```

---

## Comparaci√≥n de Arquitecturas

| Arquitectura | Calidad | Velocidad | Storage | Uso |
|--------------|---------|-----------|---------|-----|
| **Bi-Encoder** | Buena | Muy r√°pida | Bajo | Default |
| **Cross-Encoder** | Excelente | Muy lenta | N/A | Re-ranking |
| **ColBERT** | Muy buena | R√°pida | Alto | Precision cr√≠tica |

### Visualizaci√≥n del trade-off:

```
                    CALIDAD
                       ‚Üë
                       ‚îÇ
    Cross-Encoder ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚òÖ
                       ‚îÇ
           ColBERT ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚òÖ
                       ‚îÇ
        Bi-Encoder ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚òÖ
                       ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí VELOCIDAD

                    STORAGE
                       ‚Üë
           ColBERT ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚òÖ (mucho)
                       ‚îÇ
        Bi-Encoder ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚òÖ (poco)
                       ‚îÇ
    Cross-Encoder ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ N/A (no pre-almacena)
```

---

## Cu√°ndo Usar Cada Uno

### Bi-Encoder (Default):

```
‚úÖ La mayor√≠a de los casos
‚úÖ Necesit√°s velocidad
‚úÖ Storage es una preocupaci√≥n
‚úÖ Calidad "buena" es suficiente
```

### Cross-Encoder:

```
‚úÖ Re-ranking (no como b√∫squeda principal)
‚úÖ Cuando la calidad es cr√≠tica
‚úÖ Sobre un conjunto PEQUE√ëO de documentos pre-filtrados
```

### ColBERT:

```
‚úÖ Dominios donde precision es cr√≠tica (legal, m√©dico)
‚úÖ Ten√©s storage disponible
‚úÖ Necesit√°s velocidad cercana a bi-encoder
‚úÖ Pero calidad cercana a cross-encoder
```

---

## Aplicaci√≥n para DONA üéØ

### Recomendaci√≥n para DONA:

```
FASE 1: Bi-Encoder (default)
‚îú‚îÄ‚îÄ Suficiente para cat√°logo de productos
‚îú‚îÄ‚îÄ R√°pido y econ√≥mico
‚îî‚îÄ‚îÄ Evaluar m√©tricas

FASE 2: Si precision es problema
‚îú‚îÄ‚îÄ Cross-Encoder para RE-RANKING
‚îú‚îÄ‚îÄ Bi-encoder trae 20 docs
‚îú‚îÄ‚îÄ Cross-encoder re-rankea ‚Üí top 5
‚îî‚îÄ‚îÄ (Pr√≥ximo cap√≠tulo)

FASE 3: Si storage no es problema
‚îú‚îÄ‚îÄ Considerar ColBERT
‚îú‚îÄ‚îÄ Para documentaci√≥n t√©cnica compleja
‚îî‚îÄ‚îÄ Donde interacciones contextuales importan
```

### Ejemplo de cu√°ndo ColBERT ayudar√≠a:

```
Prompt: "hierro para columna de 3 metros"

Documento: "Varilla de acero estructural para elementos verticales 
            de hasta 300cm de altura"

Bi-encoder: Puede no captar que:
‚îú‚îÄ‚îÄ "hierro" ‚âà "acero"
‚îú‚îÄ‚îÄ "columna" ‚âà "elementos verticales"
‚îî‚îÄ‚îÄ "3 metros" = "300cm"

ColBERT: Compara token por token
‚îú‚îÄ‚îÄ "hierro" encuentra "acero" (similar)
‚îú‚îÄ‚îÄ "columna" encuentra "verticales" (similar)
‚îî‚îÄ‚îÄ "3" encuentra "300" (relacionado contextualmente)
```

---

## Resumen del Cap√≠tulo 24

| Arquitectura | C√≥mo embebe | Pre-proceso | Calidad | Velocidad |
|--------------|-------------|-------------|---------|-----------|
| **Bi-Encoder** | 1 vector por doc | S√≠ | Buena | Muy r√°pida |
| **Cross-Encoder** | Prompt+Doc juntos | No | Excelente | Muy lenta |
| **ColBERT** | 1 vector por token | S√≠ | Muy buena | R√°pida |

---

## Key Takeaway:

> "Bi-encoder es el default. Cross-encoder es demasiado lento para b√∫squeda directa, pero es excelente para re-ranking. ColBERT es un balance entre ambos, a costa de mucho m√°s storage."

---

## Pr√≥ximo: Re-ranking con Cross-Encoders

C√≥mo usar cross-encoders a pesar de su ineficiencia.

---
