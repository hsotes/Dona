# CapÃ­tulo 32: TÃ©cnicas Avanzadas de Prompting

---

## Overview

> "Una vez que tenÃ©s un template bÃ¡sico de prompt para tu sistema RAG, podÃ©s empezar a probar tÃ©cnicas de prompt engineering mÃ¡s avanzadas."

---

## TÃ©cnica 1: In-Context Learning

### La idea:

```
Ayudar al LLM a aprender quÃ© tipo de output querÃ©s
agregando EJEMPLOS al prompt.
```

### Ejemplo:

```
Si estÃ¡s construyendo un chatbot de customer service:

â”œâ”€â”€ Incluir ejemplos de requests de clientes anteriores
â”œâ”€â”€ Incluir respuestas de alta calidad a esos requests
â””â”€â”€ El LLM aprende el tono y estructura de esas respuestas
```

### Nomenclatura:

```
FEW-SHOT LEARNING: Varios ejemplos en el prompt
ONE-SHOT LEARNING: Un solo ejemplo en el prompt
ZERO-SHOT: Sin ejemplos (lo que venÃ­as haciendo)
```

---

### ImplementaciÃ³n de In-Context Learning

#### OpciÃ³n 1: Ejemplos hardcodeados

```python
SYSTEM_PROMPT = """
Sos un asistente de ventas. RespondÃ© como en estos ejemplos:

EJEMPLO 1:
Cliente: "Â¿Tienen cemento?"
Asistente: "Â¡SÃ­! Tenemos varias opciones de cemento. El Portland 
Tipo I de Loma Negra estÃ¡ a $8,500 la bolsa de 50kg. Â¿CuÃ¡ntas 
bolsas necesitÃ¡s?"

EJEMPLO 2:
Cliente: "Â¿CuÃ¡nto sale el hierro?"
Asistente: "El hierro del 8 estÃ¡ a $X el metro, y el del 10 a $Y. 
Â¿Para quÃ© uso lo necesitÃ¡s? AsÃ­ te recomiendo el mÃ¡s adecuado."

Ahora respondÃ© a la siguiente consulta:
"""
```

#### OpciÃ³n 2: RAG para ejemplos dinÃ¡micos

```python
# Indexar conversaciones exitosas en vector DB
def get_example_conversations(query):
    # Buscar conversaciones similares anteriores
    examples = conversation_db.query.hybrid(
        query=query,
        limit=2
    )
    return examples

# Inyectar ejemplos relevantes al prompt
examples = get_example_conversations(user_query)
prompt = f"""
Ejemplos de conversaciones exitosas sobre temas similares:

{format_examples(examples)}

Ahora respondÃ©:
{user_query}
"""
```

> "De muchas formas, esto es RAG normal, pero el hecho de que estÃ¡s recuperando especÃ­ficamente RESPUESTAS DE EJEMPLO puede mejorar aÃºn mÃ¡s la calidad."

---

## TÃ©cnica 2: Chain-of-Thought (CoT)

### La idea:

```
Animar al LLM a RAZONAR paso a paso
antes de dar la respuesta final.
```

### ImplementaciÃ³n con Scratchpad:

```python
SYSTEM_PROMPT = """
Cuando respondas preguntas complejas, primero pensÃ¡ en voz alta
dentro de tags <scratchpad>. Estos tags son para organizar 
tus pensamientos y NO son parte de la respuesta final.

Formato:
<scratchpad>
[Tu razonamiento paso a paso aquÃ­]
</scratchpad>

[Tu respuesta final aquÃ­]
"""
```

### Ejemplo de output:

```
Usuario: "Â¿QuÃ© materiales necesito para una losa de 20mÂ²?"

<scratchpad>
1. Para calcular materiales de losa necesito saber:
   - Ãrea: 20mÂ² (dado)
   - Espesor tÃ­pico: 10-12cm para losa residencial
   
2. Calculando para espesor de 10cm:
   - Volumen de hormigÃ³n: 20mÂ² Ã— 0.10m = 2mÂ³
   - Cemento: ~300kg/mÂ³ Ã— 2mÂ³ = 600kg = 12 bolsas
   - Arena: ~0.5mÂ³/mÂ³ Ã— 2mÂ³ = 1mÂ³
   - Piedra: ~0.7mÂ³/mÂ³ Ã— 2mÂ³ = 1.4mÂ³
   
3. Hierro para malla:
   - Malla tÃ­pica: cada 15cm
   - Hierro del 6 o del 8 segÃºn carga
</scratchpad>

Para una losa de 20mÂ² con espesor de 10cm, vas a necesitar 
aproximadamente:
- **Cemento**: 12 bolsas de 50kg
- **Arena**: 1mÂ³
- **Piedra**: 1.5mÂ³
- **Hierro**: Malla con hierro del 6 cada 15cm

Â¿QuerÃ©s que te arme un presupuesto con precios actuales?
```

---

### Por quÃ© funciona CoT:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   1. Le das al LLM un "scratchpad" para organizar       â”‚
â”‚      sus pensamientos antes de responder.              â”‚
â”‚                                                         â”‚
â”‚   2. El enfoque incremental aumenta la probabilidad    â”‚
â”‚      de respuestas mÃ¡s precisas.                       â”‚
â”‚                                                         â”‚
â”‚   3. Es mÃ¡s fÃ¡cil detectar DÃ“NDE falla el razonamiento â”‚
â”‚      cuando el LLM "muestra su trabajo".               â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## TÃ©cnica 3: Reasoning Models

### La evoluciÃ³n de CoT:

```
Las estrategias de razonamiento fueron tan exitosas que
ahora hay LLMs diseÃ±ados como "reasoning models" de fÃ¡brica.

Ejemplos:
â”œâ”€â”€ OpenAI o1 / o1-mini
â”œâ”€â”€ DeepSeek R1
â”œâ”€â”€ Claude con extended thinking
â””â”€â”€ Otros "thinking" models
```

### CÃ³mo funcionan internamente:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   1. REASONING TOKENS (interno)                        â”‚
â”‚      PlanificaciÃ³n, consideraciÃ³n de opciones          â”‚
â”‚      Como el scratchpad pero automÃ¡tico                â”‚
â”‚                                                         â”‚
â”‚   2. RESPONSE TOKENS (lo que ves)                      â”‚
â”‚      La respuesta final al usuario                     â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Algunos proveedores solo muestran response tokens.
Otros te dejan ver los reasoning tokens tambiÃ©n.
```

### Trade-offs de Reasoning Models:

```
âœ… VENTAJAS:
â”œâ”€â”€ MÃ¡s precisos en tareas complejas
â”œâ”€â”€ Excelentes en cÃ³digo, matemÃ¡ticas, planificaciÃ³n
â”œâ”€â”€ Buenos evaluando relevancia de documentos
â””â”€â”€ Mejores incorporando informaciÃ³n en respuestas complejas

âŒ DESVENTAJAS:
â”œâ”€â”€ MÃ¡s LENTOS (generan muchos reasoning tokens)
â”œâ”€â”€ MÃ¡s CAROS (pagÃ¡s por todos los tokens)
â””â”€â”€ Los reasoning tokens son tokens regulares con costo
```

---

### Prompting para Reasoning Models

#### Lo que NO necesitÃ¡s:

```
âŒ "PensÃ¡ paso a paso" â†’ ya lo hacen automÃ¡ticamente
âŒ In-context learning â†’ pueden confundir ejemplos con la pregunta actual
```

#### Lo que SÃ funciona:

```
âœ… Objetivos especÃ­ficos a alcanzar
âœ… Formato de respuesta muy especÃ­fico
âœ… Principios guÃ­a de alto nivel
âœ… Enfoques a tomar o evitar
âœ… Context dump completo de documentos RAG
```

---

## GestiÃ³n del Context Window

### El problema:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   TODO usa context window:                             â”‚
â”‚   â”œâ”€â”€ System prompt                                    â”‚
â”‚   â”œâ”€â”€ In-context learning examples                     â”‚
â”‚   â”œâ”€â”€ Retrieved documents                              â”‚
â”‚   â”œâ”€â”€ Conversation history                             â”‚
â”‚   â”œâ”€â”€ Reasoning tokens (si reasoning model)            â”‚
â”‚   â””â”€â”€ Generated response                               â”‚
â”‚                                                         â”‚
â”‚   Es MUY fÃ¡cil llenarlo rÃ¡pidamente si no prestÃ¡s      â”‚
â”‚   atenciÃ³n.                                            â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### SoluciÃ³n 1: Validar valor agregado

```
Para single-turn conversations:

Si una tÃ©cnica (CoT, few-shot) no estÃ¡ dando mejor performance:
â†’ REMOVELA del sistema

No agregues complejidad sin beneficio medible.
```

### SoluciÃ³n 2: Context Pruning

```
Para multi-turn conversations:

OPCIÃ“N A: Fixed window
â””â”€â”€ Mantener solo los Ãºltimos N mensajes (ej: Ãºltimos 5)

OPCIÃ“N B: Summarization
â””â”€â”€ Usar LLM separado para resumir mensajes viejos
â””â”€â”€ Preserva puntos clave, reduce tokens

OPCIÃ“N C: Drop reasoning tokens
â””â”€â”€ En reasoning models, solo guardar response tokens
â””â”€â”€ No guardar el "pensamiento" en el historial

OPCIÃ“N D: Drop old RAG context
â””â”€â”€ Solo incluir chunks para la pregunta ACTUAL
â””â”€â”€ No arrastrar chunks de preguntas anteriores
```

---

### Ejemplo de Context Pruning para DONA:

```python
def prune_conversation(messages, max_messages=6):
    """Mantener solo los Ãºltimos N mensajes"""
    if len(messages) <= max_messages:
        return messages
    
    # Siempre mantener system prompt
    system = [m for m in messages if m['role'] == 'system']
    
    # Ãšltimos N mensajes user/assistant
    recent = [m for m in messages if m['role'] != 'system'][-max_messages:]
    
    return system + recent


def prune_with_summary(messages, llm, max_messages=6):
    """Resumir mensajes viejos"""
    if len(messages) <= max_messages:
        return messages
    
    system = [m for m in messages if m['role'] == 'system']
    conversation = [m for m in messages if m['role'] != 'system']
    
    # Mensajes viejos a resumir
    old_messages = conversation[:-max_messages]
    recent_messages = conversation[-max_messages:]
    
    # Resumir con LLM
    summary = llm.generate(
        prompt=f"ResumÃ­ esta conversaciÃ³n en 2-3 oraciones: {old_messages}"
    )
    
    # Inyectar resumen como contexto
    summary_message = {
        "role": "system",
        "content": f"Resumen de la conversaciÃ³n anterior: {summary}"
    }
    
    return system + [summary_message] + recent_messages
```

---

## AplicaciÃ³n para DONA ğŸ¯

### Few-Shot Learning para DONA:

```python
DONA_EXAMPLES = """
EJEMPLO 1:
Cliente: "cuanto sale el cemento"
DONA: "El Cemento Portland de Loma Negra estÃ¡ a $8,500 la bolsa 
de 50kg. TambiÃ©n tenemos Holcim a $8,200. Â¿CuÃ¡ntas bolsas necesitÃ¡s?"

EJEMPLO 2:
Cliente: "necesito fierro"
DONA: "Â¿QuÃ© diÃ¡metro necesitÃ¡s? Tenemos:
- Hierro del 6: $X/metro
- Hierro del 8: $Y/metro  
- Hierro del 10: $Z/metro
Â¿Es para columnas, vigas, o losa?"
"""
```

### CoT para consultas complejas:

```python
# Activar CoT solo para preguntas de cÃ¡lculo/presupuesto
if es_pregunta_compleja(user_query):
    prompt += """
    <scratchpad>
    Antes de responder, calculÃ¡:
    1. QuÃ© productos se necesitan
    2. Cantidades aproximadas
    3. Precios actuales del contexto
    </scratchpad>
    """
```

### Context Pruning para DONA:

```python
DONA_CONTEXT_CONFIG = {
    "max_history_messages": 6,      # Ãšltimos 3 turnos
    "max_retrieved_docs": 5,        # Solo para pregunta actual
    "include_reasoning_in_history": False,
    "summarize_after": 10           # Resumir si > 10 mensajes
}
```

---

## CuÃ¡ndo Usar Cada TÃ©cnica

| TÃ©cnica | CuÃ¡ndo usar | CuÃ¡ndo NO usar |
|---------|-------------|----------------|
| **Few-Shot** | Formato especÃ­fico de respuesta | Ya funciona bien sin ejemplos |
| **CoT** | Razonamiento complejo, cÃ¡lculos | Preguntas simples |
| **Reasoning Model** | Tareas complejas, presupuesto disponible | Preguntas simples, presupuesto bajo |
| **Context Pruning** | Conversaciones largas | Conversaciones cortas |

---

## Resumen del CapÃ­tulo 32

| TÃ©cnica | QuÃ© hace | Costo |
|---------|----------|-------|
| **Few-Shot** | Ejemplos en el prompt | MÃ¡s tokens en prompt |
| **Chain-of-Thought** | Razonamiento paso a paso | MÃ¡s tokens generados |
| **Reasoning Models** | CoT automÃ¡tico interno | MÃ¡s lento y caro |
| **Context Pruning** | Reducir historial | Complejidad de implementaciÃ³n |

---

## Key Takeaway:

> "Tu sistema RAG no necesariamente necesita emplear estas tÃ©cnicas avanzadas. Un template simple y un system prompt bien escrito podrÃ­an ser todo lo que necesitÃ¡s. Cuando se trata de tÃ©cnicas mÃ¡s avanzadas, te aconsejo agregarlas solo despuÃ©s de que estÃ© claro que las necesitÃ¡s."

---

## PrÃ³ximo: Grounding y Hallucinations

CÃ³mo asegurar que el LLM se base en los documentos recuperados.

---
