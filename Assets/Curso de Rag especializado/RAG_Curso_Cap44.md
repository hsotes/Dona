# CapÃ­tulo 44: Gestionando Costos en RAG

---

## El Tema Favorito de Todo Ingeniero: El Presupuesto

> "Cuando diseÃ±Ã¡s tu primer sistema RAG, probablemente te enfoques en explorar quÃ© es posible y obtener un prototipo funcionando. Cuando empezÃ¡s a escalar a cientos, miles, o incluso millones de requests, las consideraciones de costo se vuelven cada vez mÃ¡s importantes."

---

## Los Dos Mayores Costos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   En una aplicaciÃ³n RAG tÃ­pica:                        â”‚
â”‚                                                         â”‚
â”‚   1. VECTOR DATABASE                                   â”‚
â”‚   2. LARGE LANGUAGE MODELS                             â”‚
â”‚                                                         â”‚
â”‚   Estos son los principales drivers de costo.          â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Estrategia 1: Modelos MÃ¡s PequeÃ±os

### La idea:

```
Experimentar con SMALLER MODELS:

â”œâ”€â”€ El LLM principal (genera respuesta final)
â”œâ”€â”€ Router LLMs en sistemas agentic
â””â”€â”€ Otros LLMs auxiliares

PodrÃ­as lograr SIMILAR CALIDAD con modelos
mÃ¡s pequeÃ±os = mÃ¡s baratos.
```

### QuÃ© significa "mÃ¡s pequeÃ±o":

```
MENOS PARÃMETROS:
â”œâ”€â”€ GPT-4 (~1.8T params) â†’ GPT-3.5 (~175B params)
â”œâ”€â”€ Claude Opus â†’ Claude Haiku
â””â”€â”€ Llama 70B â†’ Llama 8B

QUANTIZED:
â”œâ”€â”€ 16-bit â†’ 8-bit o 4-bit
â””â”€â”€ Mismo modelo, menos precisiÃ³n
```

### CuÃ¡ndo funciona bien:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   Modelos pequeÃ±os funcionan especialmente bien si:    â”‚
â”‚                                                         â”‚
â”‚   â”œâ”€â”€ El LLM hace un NÃšMERO LIMITADO de tareas        â”‚
â”‚   â”œâ”€â”€ Las tareas son relativamente SIMPLES             â”‚
â”‚   â””â”€â”€ PodÃ©s FINE-TUNEAR para tu dominio especÃ­fico    â”‚
â”‚                                                         â”‚
â”‚   Fine-tuning de un modelo pequeÃ±o puede dar           â”‚
â”‚   buenos resultados a bajo costo.                      â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Estrategia 2: Limitar Tokens

### Input tokens:

```
RAG prompts pueden CRECER RÃPIDAMENTE:
â”œâ”€â”€ System prompt
â”œâ”€â”€ Conversation history
â”œâ”€â”€ Retrieved documents (muchos chunks largos)
â””â”€â”€ User query

SOLUCIONES:
â”œâ”€â”€ Reducir TOP-K (menos docs recuperados)
â”œâ”€â”€ Chunks mÃ¡s cortos
â”œâ”€â”€ Summarization de documentos
â””â”€â”€ Context pruning en conversaciones
```

### Output tokens:

```
LLMs pueden ser LONG-WINDED:
PagÃ¡s por CADA token que generan.

SOLUCIONES:
â”œâ”€â”€ System prompt que pide respuestas CONCISAS
â”œâ”€â”€ LÃ­mite firme de tokens (max_tokens)
â””â”€â”€ Instrucciones especÃ­ficas de longitud
```

### El rol de observabilidad:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   Ya sea reduciendo tamaÃ±o de modelo o largo de prompt:â”‚
â”‚                                                         â”‚
â”‚   Un pipeline de observabilidad robusto te permite:    â”‚
â”‚   â”œâ”€â”€ Evaluar impacto de los cambios                  â”‚
â”‚   â””â”€â”€ Decidir si el trade-off vale la pena            â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Estrategia 3: Hardware Dedicado

### El problema con APIs:

```
Cloud LLM providers (Together AI, AWS, Google):
â”œâ”€â”€ Inference endpoints convenientes
â”œâ”€â”€ Ideales para prototipos
â””â”€â”€ PERO: PagÃ¡s por TOKEN

A escala (miles/millones de requests):
= Puede ser MUY caro
```

### La alternativa:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   DEDICATED HARDWARE:                                  â”‚
â”‚                                                         â”‚
â”‚   Alquilar GPUs dedicadas de los mismos providers     â”‚
â”‚   para correr tus modelos.                             â”‚
â”‚                                                         â”‚
â”‚   PRICING: Por HORA (no por token)                    â”‚
â”‚                                                         â”‚
â”‚   A escala, el ahorro puede ser MUY SIGNIFICATIVO.    â”‚
â”‚                                                         â”‚
â”‚   BONUS: Mejor reliability                             â”‚
â”‚   (hardware solo sirve TU trÃ¡fico)                    â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CuÃ¡ndo conviene:

```
PROTOTYPE / BAJO VOLUMEN:
â†’ API pay-per-token (simple, flexible)

ESCALA / ALTO VOLUMEN:
â†’ Dedicated hardware (mÃ¡s barato por request)
```

---

## Estrategia 4: Gestionar Memoria del Vector DB

### Los tres tipos de memoria:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   TIPO         â”‚ VELOCIDAD â”‚ COSTO                     â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚   RAM          â”‚ MÃ¡s rÃ¡pidoâ”‚ MÃ¡s caro                  â”‚
â”‚   Disk         â”‚ Medio     â”‚ Medio                     â”‚
â”‚   Cloud Object â”‚ MÃ¡s lento â”‚ MÃ¡s barato                â”‚
â”‚                                                         â”‚
â”‚   RAM es VARIAS VECES mÃ¡s caro que Disk               â”‚
â”‚   Disk es VARIAS VECES mÃ¡s caro que Cloud Object      â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### QuÃ© poner dÃ³nde:

```
EN RAM (caro pero rÃ¡pido):
â”œâ”€â”€ HNSW index
â””â”€â”€ Datos que necesitan acceso instantÃ¡neo

EN DISK (balance):
â”œâ”€â”€ Contenido de documentos mÃ¡s accedidos
â””â”€â”€ Metadata frecuente

EN CLOUD OBJECT STORAGE (barato pero lento):
â”œâ”€â”€ Documentos raramente accedidos
â”œâ”€â”€ Archivos histÃ³ricos
â””â”€â”€ Backups
```

### El principio:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   Solo pagÃ¡ por almacenamiento rÃ¡pido y caro          â”‚
â”‚   si realmente beneficia la performance.              â”‚
â”‚                                                         â”‚
â”‚   Muchos vector DBs tienen features para:             â”‚
â”‚   â”œâ”€â”€ Monitorear este trade-off                       â”‚
â”‚   â””â”€â”€ Mover datos dinÃ¡micamente entre tiers           â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Estrategia 5: Multi-Tenancy

### El escenario:

```
1 millÃ³n de documentos
owned by
1,000 usuarios diferentes

Cada usuario solo puede acceder a SUS documentos.
= Cada usuario tiene su propio HNSW index.
```

### La optimizaciÃ³n:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   CARGAR datos de un tenant en RAM solo cuando         â”‚
â”‚   es NECESARIO.                                        â”‚
â”‚                                                         â”‚
â”‚   EJEMPLOS:                                            â”‚
â”‚                                                         â”‚
â”‚   â”œâ”€â”€ Cargar cuando el cliente HACE LOGIN              â”‚
â”‚   â”‚   (no antes)                                       â”‚
â”‚                                                         â”‚
â”‚   â”œâ”€â”€ Tenants europeos â†’ storage lento durante         â”‚
â”‚   â”‚   la NOCHE en Europa                              â”‚
â”‚                                                         â”‚
â”‚   â””â”€â”€ Tenants inactivos â†’ mover a cloud storage       â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Beneficio:

```
Organizar informaciÃ³n por tenant hace FÃCIL
mover datos in/out de memoria cara de manera eficiente.
```

---

## Resumen de Optimizaciones de Costo

| Componente | Estrategia | Ahorro |
|------------|------------|--------|
| **LLM** | Modelos mÃ¡s pequeÃ±os | Significativo |
| **LLM** | Reducir tokens input/output | Proporcional |
| **LLM** | Hardware dedicado (a escala) | Muy significativo |
| **Vector DB** | Quantization de vectores | 4-32x memoria |
| **Vector DB** | Tiered storage (RAM/Disk/Cloud) | Variable |
| **Vector DB** | Multi-tenancy + lazy loading | Variable |

---

## AplicaciÃ³n para DONA ğŸ¯

### AnÃ¡lisis de costos para DONA:

```python
DONA_COST_ANALYSIS = {
    "llm_costs": {
        "current": {
            "model": "gpt-3.5-turbo",
            "avg_input_tokens": 1200,
            "avg_output_tokens": 150,
            "cost_per_query": 0.002  # ~$2/1000 queries
        },
        "optimized": {
            "reduce_top_k": "5 â†’ 3 docs = 30% menos input",
            "concise_prompt": "Respuestas cortas = 50% menos output",
            "potential_savings": "~40%"
        }
    },
    
    "vector_db_costs": {
        "current": {
            "products": 100_000,
            "vector_size": "3KB each",
            "total": "300MB in RAM"
        },
        "optimized": {
            "8bit_quantization": "75MB (75% ahorro)",
            "tiered_storage": "Solo productos activos en RAM"
        }
    }
}
```

### Estrategias especÃ­ficas para DONA:

```python
# 1. REDUCIR TOKENS
DONA_CONCISE_PROMPT = """
RespondÃ© en 2-3 oraciones mÃ¡ximo.
Solo mencionÃ¡ precio y disponibilidad.
No des explicaciones tÃ©cnicas a menos que pregunten.
"""

# 2. TIERED STORAGE POR ACTIVIDAD DE PRODUCTO
def categorize_products():
    return {
        "hot": "Productos vendidos en Ãºltimos 30 dÃ­as â†’ RAM",
        "warm": "Productos consultados en Ãºltimos 90 dÃ­as â†’ Disk",
        "cold": "Resto â†’ Cloud Storage"
    }

# 3. MODELO SIZING
DONA_MODEL_STRATEGY = {
    "high_volume_simple": {
        "queries": ["consulta_precio", "consulta_stock"],
        "model": "gpt-3.5-turbo",  # Barato y suficiente
        "reasoning": "Tareas simples, no necesita modelo grande"
    },
    "complex_recommendations": {
        "queries": ["recomendacion", "calculo"],
        "model": "gpt-4",  # Cuando se necesita
        "reasoning": "Vale la pena para calidad"
    }
}
```

### ProyecciÃ³n de costos para DONA:

```
ESCENARIO: 10,000 queries/dÃ­a

SIN OPTIMIZAR:
â”œâ”€â”€ LLM: $20/dÃ­a ($600/mes)
â”œâ”€â”€ Vector DB RAM: $50/mes
â””â”€â”€ Total: ~$650/mes

CON OPTIMIZACIONES:
â”œâ”€â”€ LLM: $12/dÃ­a (reducir tokens)
â”œâ”€â”€ Vector DB: $20/mes (quantization + tiering)
â””â”€â”€ Total: ~$380/mes

AHORRO: ~40%
```

### Decisiones segÃºn escala para DONA:

```
< 1,000 queries/dÃ­a:
â†’ API pay-per-token
â†’ Full precision vectors
â†’ Simple setup

1,000 - 100,000 queries/dÃ­a:
â†’ API pay-per-token
â†’ 8-bit quantized vectors
â†’ Token optimization

> 100,000 queries/dÃ­a:
â†’ Considerar dedicated hardware
â†’ Binary vectors + rescoring
â†’ Multi-tenancy si mÃºltiples corralones
```

---

## Key Takeaways:

```
1. DOS MAYORES COSTOS: LLM y Vector Database

2. LLM SAVINGS:
   â”œâ”€â”€ Modelos mÃ¡s pequeÃ±os
   â”œâ”€â”€ Menos tokens (input y output)
   â””â”€â”€ Hardware dedicado a escala

3. VECTOR DB SAVINGS:
   â”œâ”€â”€ Quantization (4-32x)
   â”œâ”€â”€ Tiered storage (RAM/Disk/Cloud)
   â””â”€â”€ Multi-tenancy + lazy loading

4. SIEMPRE: Medir impacto en calidad
   antes de adoptar optimizaciones

5. El principio: Entender la FUENTE de tus costos
   y asegurar que estÃ©n justificados por performance
```

---

## PrÃ³ximo: Trade-offs de Latencia

Optimizando velocidad de respuesta.

---
