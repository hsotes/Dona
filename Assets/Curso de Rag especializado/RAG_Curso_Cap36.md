# CapÃ­tulo 36: Fine-Tuning vs RAG

---

## Dos TÃ©cnicas para Mejorar LLMs

> "Mientras RAG es un approach popular y poderoso para mejorar la performance de un LLM, otra tÃ©cnica llamada fine-tuning tambiÃ©n se usa frecuentemente."

---

## Â¿QuÃ© es Fine-Tuning?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   FINE-TUNING:                                         â”‚
â”‚   Re-entrenar un LLM con TUS propios datos             â”‚
â”‚   para actualizar sus parÃ¡metros internos.             â”‚
â”‚                                                         â”‚
â”‚   VS                                                   â”‚
â”‚                                                         â”‚
â”‚   RAG:                                                 â”‚
â”‚   Agregar informaciÃ³n al PROMPT sin cambiar el modelo. â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Supervised Fine-Tuning (SFT)

### CÃ³mo funciona:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   1. Dataset etiquetado del dominio objetivo:          â”‚
â”‚      â”œâ”€â”€ Instrucciones/preguntas (input)               â”‚
â”‚      â””â”€â”€ Respuestas correctas esperadas (output)       â”‚
â”‚                                                         â”‚
â”‚   2. Feed al modelo las instrucciones                  â”‚
â”‚                                                         â”‚
â”‚   3. Comparar output con respuestas correctas          â”‚
â”‚                                                         â”‚
â”‚   4. Ajustar parÃ¡metros internos para                  â”‚
â”‚      alinearse mejor con las respuestas correctas      â”‚
â”‚                                                         â”‚
â”‚   Similar al entrenamiento inicial,                    â”‚
â”‚   pero con dataset de dominio especÃ­fico.              â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Ejemplo: Dominio MÃ©dico

### Antes del fine-tuning:

```
Prompt: "Paciente con dolor articular, rash en piel, 
         sensibilidad al sol"

LLM genÃ©rico: "Estos sÃ­ntomas podrÃ­an tener varias 
causas. Te recomiendo consultar a un mÃ©dico."

â†’ Respuesta GENÃ‰RICA en tono GENÃ‰RICO
```

### DespuÃ©s del fine-tuning:

```
Mismo prompt...

LLM fine-tuned: "Estos sÃ­ntomas son consistentes con 
Lupus Eritematoso SistÃ©mico (LES). La trÃ­ada de 
artralgia, rash malar y fotosensibilidad es 
caracterÃ­stica. Recomiendo: ANA, anti-dsDNA, 
complemento C3/C4..."

â†’ Respuesta mÃ¡s PRECISA, DETALLADA, y en ESTILO mÃ©dico
```

---

## Trade-offs del Fine-Tuning

### Ventaja:

```
âœ… Performance MEJORADA en el dominio objetivo
âœ… Respuestas mÃ¡s especializadas
âœ… Estilo/tono apropiado para el dominio
```

### Desventaja:

```
âŒ Performance DISMINUIDA en OTROS dominios

El proceso de fine-tuning solo optimiza para el dominio target.
Los ajustes pueden degradar performance en otras Ã¡reas.
```

### CuÃ¡ndo vale la pena:

```
Si el modelo SOLO se usarÃ¡ en el dominio especializado:
â†’ El trade-off generalmente vale la pena

Ejemplo: Router en sistema agentic
â”œâ”€â”€ Solo determina si un prompt necesita retrieval
â”œâ”€â”€ Feliz de usar modelo pequeÃ±o
â””â”€â”€ Heavy fine-tuning para ESA sola tarea
```

---

## Fine-Tuning NO EnseÃ±a Info Nueva

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   IMPORTANTE:                                          â”‚
â”‚                                                         â”‚
â”‚   Fine-tuning tiene mayor impacto en:                  â”‚
â”‚   â”œâ”€â”€ CÃ“MO responde (palabras, estilo, estructura)     â”‚
â”‚   â””â”€â”€ No tanto en QUÃ‰ INFORMACIÃ“N conoce              â”‚
â”‚                                                         â”‚
â”‚   Si querÃ©s que el LLM SEPA informaciÃ³n nueva:         â”‚
â”‚   â†’ RAG es la mejor soluciÃ³n                           â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## El Consenso Actual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   RAG = mejor para KNOWLEDGE INJECTION                 â”‚
â”‚   (inyectar informaciÃ³n nueva)                         â”‚
â”‚                                                         â”‚
â”‚   FINE-TUNING = mejor para DOMAIN ADAPTATION           â”‚
â”‚   (especializar en tareas/dominios)                    â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CuÃ¡ndo usar cada uno:

| Necesidad | SoluciÃ³n |
|-----------|----------|
| Acceso a informaciÃ³n nueva | RAG |
| Especializarse en un dominio | Fine-tuning |
| Manejar UN tipo especÃ­fico de tarea | Fine-tuning |
| Routing en sistema agentic | Fine-tuning |
| InformaciÃ³n que cambia frecuentemente | RAG |
| Estilo/tono especÃ­fico | Fine-tuning |

---

## RAG + Fine-Tuning Juntos

### CombinaciÃ³n poderosa:

```
Fine-tune un modelo especÃ­ficamente para 
INCORPORAR informaciÃ³n recuperada en sus respuestas.

= Especializar el modelo en su ROL dentro del sistema RAG.
```

### Ejemplo:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   MODELO FINE-TUNED PARA RAG:                          â”‚
â”‚                                                         â”‚
â”‚   Entrenado para:                                      â”‚
â”‚   â”œâ”€â”€ Identificar info relevante en el contexto       â”‚
â”‚   â”œâ”€â”€ Citar fuentes correctamente                     â”‚
â”‚   â”œâ”€â”€ Admitir cuando no hay info suficiente           â”‚
â”‚   â””â”€â”€ Formato de respuesta especÃ­fico                 â”‚
â”‚                                                         â”‚
â”‚   +                                                    â”‚
â”‚                                                         â”‚
â”‚   RAG provee la informaciÃ³n actual                     â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Opciones PrÃ¡cticas

### No necesitÃ¡s hacer fine-tuning vos mismo:

```
OPCIÃ“N 1: Modelos pre-fine-tuned
â”œâ”€â”€ Hugging Face tiene miles de modelos fine-tuned
â”œâ”€â”€ Para diferentes dominios y tareas
â””â”€â”€ Usarlos directamente sin fine-tuning propio

OPCIÃ“N 2: Fine-tuning as a Service
â”œâ”€â”€ OpenAI permite fine-tuning de GPT
â”œâ”€â”€ APIs que simplifican el proceso
â””â”€â”€ No necesitÃ¡s infraestructura de training

OPCIÃ“N 3: Fine-tuning propio
â”œâ”€â”€ Control total
â”œâ”€â”€ Requiere conocimiento y recursos
â””â”€â”€ Curso separado recomendado
```

---

## AplicaciÃ³n para DONA ğŸ¯

### Â¿RAG o Fine-tuning para DONA?

```
CATÃLOGO DE PRODUCTOS (precios, stock, specs):
â†’ RAG âœ…
â”œâ”€â”€ Info que cambia frecuentemente
â”œâ”€â”€ Miles de productos
â””â”€â”€ ActualizaciÃ³n sin re-entrenar

ESTILO DE COMUNICACIÃ“N (tono argentino, ventas):
â†’ Fine-tuning âœ… (o prompt engineering)
â”œâ”€â”€ CÃ³mo habla, no quÃ© sabe
â”œâ”€â”€ Consistente para todo el sistema
â””â”€â”€ No cambia frecuentemente

ROUTER PARA TIPOS DE CONSULTA:
â†’ Fine-tuning âœ…
â”œâ”€â”€ Tarea especÃ­fica y simple
â”œâ”€â”€ Modelo pequeÃ±o puede ser fine-tuned
â””â”€â”€ Una sola responsabilidad
```

### Setup hÃ­brido para DONA:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   COMPONENTE          â”‚ TÃ‰CNICA                        â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚   Router              â”‚ Fine-tuned small model        â”‚
â”‚   Retriever           â”‚ RAG (vector DB)               â”‚
â”‚   Generator           â”‚ Base model + RAG context      â”‚
â”‚   Style/Tone          â”‚ System prompt (o fine-tuning) â”‚
â”‚   Product info        â”‚ RAG (actualizable)            â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Modelos pre-fine-tuned Ãºtiles para DONA:

```
PARA ESPAÃ‘OL:
â”œâ”€â”€ Modelos fine-tuned en espaÃ±ol de Hugging Face
â””â”€â”€ Llama fine-tuned para espaÃ±ol

PARA CHAT/CUSTOMER SERVICE:
â”œâ”€â”€ Modelos instruction-tuned
â”œâ”€â”€ Chat-optimized models
â””â”€â”€ Models fine-tuned para seguir instrucciones

PARA CLASIFICACIÃ“N/ROUTING:
â”œâ”€â”€ Modelos pequeÃ±os fine-tuned para NLI
â””â”€â”€ BERT variants para clasificaciÃ³n
```

---

## Resumen del CapÃ­tulo 36

| Aspecto | RAG | Fine-Tuning |
|---------|-----|-------------|
| **Mejor para** | Knowledge injection | Domain adaptation |
| **Cambia** | El prompt | Los parÃ¡metros del modelo |
| **Info nueva** | âœ… Excelente | âŒ No tan efectivo |
| **Estilo/tono** | Limitado | âœ… Excelente |
| **ActualizaciÃ³n** | FÃ¡cil (cambiar docs) | DifÃ­cil (re-entrenar) |
| **Costo inicial** | Bajo | Alto |
| **Costo ongoing** | Por query | Una vez |

---

## Key Takeaways:

```
1. RAG y Fine-tuning NO son alternativas competidoras
   â†’ Son herramientas COMPLEMENTARIAS

2. RAG = Knowledge injection (quÃ© sabe)
   Fine-tuning = Domain adaptation (cÃ³mo responde)

3. Fine-tuning puede DEGRADAR performance en otros dominios
   â†’ Usar solo si el modelo se especializa en una tarea

4. PodÃ©s usar AMBOS juntos:
   Fine-tune para incorporar mejor la info de RAG

5. Muchos modelos pre-fine-tuned disponibles
   â†’ No siempre necesitÃ¡s hacer fine-tuning vos mismo
```

---

## PrÃ³ximo: Wrap-up MÃ³dulo 4

Resumen de LLMs para RAG.

---
