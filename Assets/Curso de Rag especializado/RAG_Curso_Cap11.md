# Cap√≠tulo 11: Keyword Search

---

## ¬øQu√© es Keyword Search?

> "Esta t√©cnica ha impulsado el retrieval en bases de datos y motores de b√∫squeda por d√©cadas. Su simplicidad y efectividad la hacen un componente clave en sistemas RAG modernos."

### La idea b√°sica:

```
Documentos que contienen MUCHAS PALABRAS del prompt
son M√ÅS PROBABLES de ser relevantes.
```

---

## Bag of Words (Bolsa de Palabras)

### El concepto:

```
Tanto el prompt como cada documento se tratan como una "bolsa de palabras"

‚îú‚îÄ‚îÄ El ORDEN de las palabras se IGNORA totalmente
‚îú‚îÄ‚îÄ Solo importa QU√â palabras hay
‚îî‚îÄ‚îÄ Y CU√ÅNTAS VECES aparece cada una
```

### Ejemplo:

```
Texto: "making pizza without a pizza oven"

Bag of Words:
‚îú‚îÄ‚îÄ pizza: 2
‚îú‚îÄ‚îÄ making: 1
‚îú‚îÄ‚îÄ without: 1
‚îú‚îÄ‚îÄ a: 1
‚îî‚îÄ‚îÄ oven: 1
```

---

## Sparse Vectors (Vectores Dispersos)

### ¬øQu√© son?

```
Un vector con un espacio para CADA palabra del vocabulario
(puede ser decenas de miles de espacios)

Cada n√∫mero cuenta cu√°ntas veces aparece esa palabra.
```

### Ejemplo visual:

```
Vocabulario: [a, making, oven, pizza, the, without, ...]
                ‚Üì
Vector:      [1,    1,     1,    2,     0,     1,    ...]

La mayor√≠a son CEROS ‚Üí por eso se llaman "sparse" (dispersos)
```

---

## Term Document Matrix (Matriz T√©rmino-Documento)

### Preparaci√≥n de la Knowledge Base:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                         ‚îÇ
‚îÇ   Para cada documento ‚Üí generar sparse vector          ‚îÇ
‚îÇ   Organizar todos los vectores en una MATRIZ           ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ              Doc1  Doc2  Doc3  Doc4  Doc5              ‚îÇ
‚îÇ   pizza       2     0     1     0     3                ‚îÇ
‚îÇ   oven        1     0     1     0     0                ‚îÇ
‚îÇ   making      1     0     0     0     1                ‚îÇ
‚îÇ   the         5     3     2     4     6                ‚îÇ
‚îÇ   without     1     0     0     0     0                ‚îÇ
‚îÇ   ...                                                   ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   Columnas = Documentos                                ‚îÇ
‚îÇ   Filas = Palabras                                     ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Tambi√©n llamado: Inverted Index (√çndice Invertido)

```
¬øPor qu√© "invertido"?

Normal: Documento ‚Üí ¬øQu√© palabras contiene?
Invertido: Palabra ‚Üí ¬øEn qu√© documentos aparece?

Esto hace MUY F√ÅCIL encontrar todos los docs que contienen una palabra.
```

---

## El Proceso de Scoring

### Paso 1: Generar vector del prompt

```
Prompt: "making pizza without a pizza oven"

Vector del prompt:
‚îú‚îÄ‚îÄ pizza: 2
‚îú‚îÄ‚îÄ oven: 1
‚îú‚îÄ‚îÄ making: 1
‚îú‚îÄ‚îÄ without: 1
‚îî‚îÄ‚îÄ a: 1
```

### Paso 2: Scoring simple (versi√≥n b√°sica)

```
Por cada KEYWORD en el prompt:
‚îú‚îÄ‚îÄ Buscar su fila en el √≠ndice
‚îú‚îÄ‚îÄ Dar 1 PUNTO a cada documento que la contenga
‚îî‚îÄ‚îÄ El documento con m√°s puntos gana

Ejemplo:
Prompt tiene 5 keywords ‚Üí m√°ximo posible = 5 puntos
```

```
              Doc1  Doc2  Doc3  Doc4  Doc5
pizza          ‚úì     -     ‚úì     -     ‚úì    (1 punto cada uno)
oven           ‚úì     -     ‚úì     -     -    (1 punto)
making         ‚úì     -     -     -     ‚úì    (1 punto)
without        ‚úì     -     -     -     -    (1 punto)
a              ‚úì     ‚úì     ‚úì     ‚úì     ‚úì    (1 punto)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOTAL:         5     1     3     1     4

Ranking: Doc1 > Doc5 > Doc3 > Doc2 = Doc4
```

---

## Mejorando el Scoring

### Problema 1: No cuenta m√∫ltiples ocurrencias

```
‚ùå Simple: Doc tiene "pizza" 10 veces = 1 punto
‚úÖ Mejorado: Doc tiene "pizza" 10 veces = 10 puntos

Soluci√≥n: Sumar el conteo de cada keyword, no solo 1
```

### Problema 2: Documentos largos tienen ventaja injusta

```
‚ùå Doc largo (10,000 palabras) con "pizza" 50 veces
   vs
   Doc corto (100 palabras) con "pizza" 5 veces

El doc largo gana solo porque es m√°s largo, no m√°s relevante.

‚úÖ Soluci√≥n: NORMALIZAR dividiendo por longitud del documento

Score normalizado = puntos / palabras_totales_del_doc
```

### Problema 3: Todas las palabras valen igual

```
‚ùå "pizza" vale lo mismo que "the"
   Pero "the" aparece en TODOS los documentos
   Mientras "pizza" es espec√≠fico y relevante

‚úÖ Soluci√≥n: IDF (Inverse Document Frequency)
```

---

## IDF: Inverse Document Frequency

### El concepto:

```
Palabras RARAS son m√°s valiosas para identificar relevancia
Palabras COMUNES no dicen mucho
```

### C√≥mo calcularlo:

```
1. Document Frequency (DF):
   DF = docs_que_contienen_palabra / total_docs

   Ejemplo (100 docs en knowledge base):
   ‚îú‚îÄ‚îÄ "pizza" aparece en 5 docs ‚Üí DF = 5/100 = 0.05
   ‚îî‚îÄ‚îÄ "the" aparece en 100 docs ‚Üí DF = 100/100 = 1.0

2. Inverse Document Frequency (IDF):
   IDF = total_docs / docs_que_contienen_palabra

   ‚îú‚îÄ‚îÄ "pizza": IDF = 100/5 = 20   (palabra rara = alto IDF)
   ‚îî‚îÄ‚îÄ "the": IDF = 100/100 = 1    (palabra com√∫n = bajo IDF)

3. Aplicar LOG para suavizar:
   (porque IDF crudo puede ser muy extremo)

   ‚îú‚îÄ‚îÄ "pizza": log(20) ‚âà 3.0
   ‚îî‚îÄ‚îÄ "the": log(1) = 0
```

---

## TF-IDF: Term Frequency - Inverse Document Frequency

### La f√≥rmula combinada:

```
TF-IDF = TF √ó IDF

Donde:
‚îú‚îÄ‚îÄ TF (Term Frequency) = cu√°ntas veces aparece la palabra en el doc
‚îî‚îÄ‚îÄ IDF = qu√© tan rara es la palabra en toda la knowledge base
```

### Actualizar la matriz:

```
Multiplicar cada fila por su IDF:

ANTES (conteos crudos):
              Doc1  Doc2  Doc3
pizza          2     0     1
the            5     3     2

DESPU√âS (TF-IDF):
              Doc1  Doc2  Doc3
pizza (√ó3.0)   6     0     3     ‚Üê palabra rara, m√°s peso
the (√ó0)       0     0     0     ‚Üê palabra com√∫n, sin peso
```

### Resultado:

```
Los documentos que:
‚îú‚îÄ‚îÄ Usan keywords FRECUENTEMENTE
‚îî‚îÄ‚îÄ Especialmente keywords RARAS en la knowledge base

...tendr√°n los scores m√°s altos.
```

---

## Ejemplo Final

```
Prompt: "making pizza without a pizza oven"

An√°lisis de keywords:
‚îú‚îÄ‚îÄ "pizza" ‚Üí raro ‚Üí IDF alto ‚Üí MUCHO peso
‚îú‚îÄ‚îÄ "oven" ‚Üí raro ‚Üí IDF alto ‚Üí MUCHO peso
‚îú‚îÄ‚îÄ "making" ‚Üí medio ‚Üí IDF medio
‚îú‚îÄ‚îÄ "without" ‚Üí com√∫n ‚Üí IDF bajo
‚îî‚îÄ‚îÄ "a" ‚Üí muy com√∫n ‚Üí IDF muy bajo (casi 0)

Documentos sobre pizza y hornos ganar√°n
aunque tambi√©n mencionen "a" y "the"
```

---

## TF-IDF es la Baseline

> "Los scores TF-IDF son un baseline est√°ndar para el performance de keyword retrieval."

```
Sistemas modernos usan una versi√≥n refinada: BM25
(pr√≥ximo cap√≠tulo)
```

---

## Aplicaci√≥n para DONA üéØ

### Keywords importantes en tu cat√°logo:

```
ALTA IDF (raras, valiosas):
‚îú‚îÄ‚îÄ "portland" (tipo espec√≠fico de cemento)
‚îú‚îÄ‚îÄ "adn42" (c√≥digo de producto)
‚îú‚îÄ‚îÄ "10mm" (medida espec√≠fica)
‚îî‚îÄ‚îÄ "acindar" (marca)

BAJA IDF (comunes, poco valor):
‚îú‚îÄ‚îÄ "material"
‚îú‚îÄ‚îÄ "construcci√≥n"
‚îú‚îÄ‚îÄ "precio"
‚îî‚îÄ‚îÄ "el", "de", "para"
```

### Ejemplo de b√∫squeda DONA:

```
Query: "hierro del 8 para construcci√≥n"

Keywords con valor:
‚îú‚îÄ‚îÄ "hierro" ‚Üí IDF medio (hay varios productos)
‚îú‚îÄ‚îÄ "8" (o "del 8") ‚Üí IDF alto (espec√≠fico)
‚îî‚îÄ‚îÄ "construcci√≥n" ‚Üí IDF muy bajo (todo es construcci√≥n)

El "8" es lo que realmente diferencia la b√∫squeda.
```

---

## Resumen del Cap√≠tulo 11

| Concepto | Explicaci√≥n |
|----------|-------------|
| **Bag of Words** | Ignorar orden, solo contar palabras |
| **Sparse Vector** | Vector con conteo de cada palabra |
| **Inverted Index** | Palabra ‚Üí documentos que la contienen |
| **TF** | Term Frequency (cu√°ntas veces en el doc) |
| **IDF** | Inverse Doc Frequency (qu√© tan rara) |
| **TF-IDF** | TF √ó IDF = score final |

---

## Key Insight:

> "Documentos con keywords frecuentes Y raras obtienen los scores m√°s altos."

---

## Pr√≥ximo: BM25

La versi√≥n refinada de TF-IDF que usan los sistemas modernos.

---
