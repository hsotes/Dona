# CapÃ­tulo 28: Arquitectura Transformer

---

## La Pregunta Fundamental

> "Tu retriever acaba de retornar documentos relevantes. Pero, Â¿por quÃ© esto funciona? Â¿CÃ³mo puede un LLM entender esa informaciÃ³n recuperada?"

---

## Historia: "Attention is All You Need" (2017)

```
Paper seminal enfocado en machine translation.

Dos componentes principales:
â”œâ”€â”€ ENCODER: Procesa el texto original (ej: pÃ¡rrafo en alemÃ¡n)
â”‚            Desarrolla entendimiento contextual profundo
â”‚
â””â”€â”€ DECODER: Usa ese entendimiento para generar nuevo texto
             (ej: versiÃ³n en inglÃ©s)
```

### En LLMs modernos:

```
LLMs: Solo usan el DECODER (generaciÃ³n de texto)

Embedding Models: Usan el ENCODER (representaciÃ³n semÃ¡ntica)
```

---

## El Viaje de un Prompt a TravÃ©s del LLM

### Paso 1: TokenizaciÃ³n

```
Prompt: "The brown dog sat next to the fox"
         â†“
Tokens: ["The", "brown", "dog", "sat", "next", "to", "the", "fox"]
```

### Paso 2: Embedding Inicial (First Guess)

```
Cada token â†’ vector denso inicial

"dog" â†’ [0.23, 0.45, -0.12, ...] (first guess)
"brown" â†’ [0.67, -0.34, 0.89, ...] (first guess)

Estos vectores son ESTÃTICOS:
El mismo token siempre recibe el mismo first guess.
```

### Paso 3: Positional Encoding

```
Cada token tambiÃ©n recibe un vector de POSICIÃ“N.

"dog" en posiciÃ³n 3 â†’ vector posicional [...]
"fox" en posiciÃ³n 8 â†’ vector posicional [...]

Esto le dice al modelo DÃ“NDE estÃ¡ cada token.
```

---

## El Mecanismo de AtenciÃ³n

### La idea:

```
Cada token MIRA a todos los otros tokens.
Ve su significado Y su posiciÃ³n.
Decide a cuÃ¡les prestar mÃ¡s ATENCIÃ“N.
```

### Ejemplo:

```
"The brown dog sat next to the red fox"

Â¿A quÃ© presta atenciÃ³n "dog"?

dog â†’ brown:  70% atenciÃ³n (lo describe directamente)
dog â†’ sat:    20% atenciÃ³n (quÃ© hace el perro)
dog â†’ otros:  10% distribuido

"Attention" = Â¿QuÃ© tokens deberÃ­an impactar mÃ¡s MI significado?
```

---

### MÃºltiples Attention Heads

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   Los modelos tienen MÃšLTIPLES attention heads         â”‚
â”‚   que se especializan en DIFERENTES relaciones.        â”‚
â”‚                                                         â”‚
â”‚   HEAD 1: Relaciones objeto-descripciÃ³n                â”‚
â”‚           fox â†’ presta atenciÃ³n a "red"                â”‚
â”‚                                                         â”‚
â”‚   HEAD 2: Relaciones espaciales                        â”‚
â”‚           fox â†’ presta atenciÃ³n a "sat", "next"        â”‚
â”‚                                                         â”‚
â”‚   HEAD 3: Relaciones gramaticales                      â”‚
â”‚           ...                                          â”‚
â”‚                                                         â”‚
â”‚   Modelos pequeÃ±os: 8-16 heads                         â”‚
â”‚   Modelos grandes: 100+ heads                          â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Resultado:

```
Cada token trackea su relaciÃ³n con TODOS los otros tokens,
y lo hace MUCHAS veces con diferentes "puntos de vista".

= RepresentaciÃ³n MUY detallada de las relaciones entre tokens.
```

---

## Feedforward Layers

### La parte mÃ¡s grande del LLM:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   FEEDFORWARD LAYERS                                   â”‚
â”‚   (La mayorÃ­a de los parÃ¡metros estÃ¡n aquÃ­)            â”‚
â”‚                                                         â”‚
â”‚   Input: Embedding original + posiciÃ³n + atenciÃ³n      â”‚
â”‚   Output: NUEVO vector para cada token                 â”‚
â”‚                                                         â”‚
â”‚   Este nuevo vector es un "second guess" del           â”‚
â”‚   significado, AHORA INFORMADO por el contexto.        â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## IteraciÃ³n: Refinando el Entendimiento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   1st pass: First guess â†’ Attention â†’ Feedforward      â”‚
â”‚             â†’ Second guess vectors                     â”‚
â”‚                                                         â”‚
â”‚   2nd pass: Second guess â†’ Attention â†’ Feedforward     â”‚
â”‚             â†’ Third guess vectors                      â”‚
â”‚                                                         â”‚
â”‚   3rd pass: Third guess â†’ Attention â†’ Feedforward      â”‚
â”‚             â†’ Fourth guess vectors                     â”‚
â”‚                                                         â”‚
â”‚   ...                                                  â”‚
â”‚                                                         â”‚
â”‚   TÃ­pico: 8 a 64 pasadas (layers)                     â”‚
â”‚   Cada pasada REFINA el entendimiento.                 â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## GeneraciÃ³n de Tokens

### Paso 1: Predecir el siguiente token

```
BasÃ¡ndose en los vectores refinados, el modelo pregunta:

"SegÃºn mis datos de entrenamiento,
 Â¿quÃ© tokens probablemente vienen despuÃ©s?"

Resultado: DistribuciÃ³n de probabilidad sobre TODO el vocabulario.

Ej: Si el vocabulario tiene 100,000 tokens:

"is"     â†’ 0.35 (35%)
"was"    â†’ 0.25 (25%)
"sat"    â†’ 0.15 (15%)
"jumped" â†’ 0.08 (8%)
...
"xyz"    â†’ 0.0001 (casi cero)
```

### Paso 2: Elegir un token

```
El LLM ELIGE un token de esta distribuciÃ³n,
pesando la elecciÃ³n por las probabilidades asignadas.

Tokens probables se eligen mÃ¡s seguido,
pero EN TEORÃA cualquier token tiene una chance.

â†’ Por eso los LLMs son INHERENTEMENTE ALEATORIOS.
```

### Paso 3: Repetir

```
Token elegido se agrega al final del prompt.

Para generar el SEGUNDO token:
â”œâ”€â”€ Repetir TODO el proceso
â”œâ”€â”€ Pero ahora considerando el nuevo token tambiÃ©n
â””â”€â”€ Nuevos tokens hacen sentido con originales Y generados

Esto continÃºa hasta:
â”œâ”€â”€ Llegar al lÃ­mite de tokens que configuraste
â””â”€â”€ O el modelo genera un token especial de "fin"
```

---

## VisualizaciÃ³n del Proceso Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   PROMPT: "What is the capital of"                     â”‚
â”‚                                                         â”‚
â”‚   1. Tokenizar â†’ ["What", "is", "the", "capital", "of"]â”‚
â”‚                                                         â”‚
â”‚   2. First guess embeddings para cada token            â”‚
â”‚                                                         â”‚
â”‚   3. Positional encodings                              â”‚
â”‚                                                         â”‚
â”‚   4. Attention (mÃºltiples heads)                       â”‚
â”‚      "capital" presta atenciÃ³n a "What" (pregunta)     â”‚
â”‚      "capital" presta atenciÃ³n a "of" (preposiciÃ³n)    â”‚
â”‚                                                         â”‚
â”‚   5. Feedforward â†’ second guess                        â”‚
â”‚                                                         â”‚
â”‚   6. Repetir 4-5 muchas veces (8-64 layers)           â”‚
â”‚                                                         â”‚
â”‚   7. Predecir siguiente token                          â”‚
â”‚      "France" â†’ 0.02                                   â”‚
â”‚      "Canada" â†’ 0.03                                   â”‚
â”‚      ...depende de quÃ© paÃ­s esperaba...                â”‚
â”‚                                                         â”‚
â”‚   8. Elegir token (ej: "France")                       â”‚
â”‚                                                         â”‚
â”‚   9. Repetir para generar mÃ¡s tokens                   â”‚
â”‚      â†’ "France is Paris"                               â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Implicaciones para RAG

### 1. Por quÃ© RAG funciona

```
Los LLMs pueden PROFUNDAMENTE entender el significado
y relevancia de la informaciÃ³n agregada al prompt.

Gracias a:
â”œâ”€â”€ Attention mechanism (entiende relaciones)
â””â”€â”€ Feedforward layers (conocimiento del mundo)

El LLM puede "leer" los documentos recuperados
y USARLOS para responder.
```

### 2. Los LLMs son inherentemente ALEATORIOS

```
âš ï¸ IMPORTANTE:

Aunque inyectes informaciÃ³n significativa en el prompt,
el LLM PUEDE elegir NO usarla para generar texto.

Por eso necesitÃ¡s:
â”œâ”€â”€ Controlar la aleatoriedad (temperature)
â”œâ”€â”€ Confirmar que el LLM se basa en la info recuperada
â””â”€â”€ TÃ©cnicas de grounding
```

### 3. Los LLMs son computacionalmente COSTOSOS

```
Generar UN SOLO TOKEN requiere mucho procesamiento.

Y el costo CRECE con la longitud del prompt/completion:
â”œâ”€â”€ Cada token necesita mirar a TODOS los otros
â”œâ”€â”€ MÃ¡s tokens = mÃ¡s comparaciones = mÃ¡s costo
â””â”€â”€ O(nÂ²) en tÃ©rminos de atenciÃ³n

La mayorÃ­a de los costos de un sistema RAG
vienen de correr estos modelos transformer.
```

---

## AplicaciÃ³n para DONA ğŸ¯

### Por quÃ© DONA puede funcionar:

```
Cuando el retriever trae info del producto:
â”œâ”€â”€ El LLM "lee" esa informaciÃ³n
â”œâ”€â”€ Attention conecta la pregunta con el contexto
â”œâ”€â”€ Feedforward usa conocimiento general
â””â”€â”€ Genera respuesta basada en el contexto
```

### Riesgos a manejar:

```
1. ALEATORIEDAD:
   El LLM puede ignorar el contexto y responder de memoria
   â†’ Necesitamos tÃ©cnicas de grounding

2. COSTO:
   Prompts largos con mucho contexto = mÃ¡s caro
   â†’ Chunking y re-ranking optimizan esto

3. CONTEXTO MEZCLADO:
   Con mÃºltiples productos en contexto, el LLM puede mezclar
   â†’ Estructurar bien el prompt
```

---

## Resumen del CapÃ­tulo 28

| Componente | QuÃ© hace |
|------------|----------|
| **TokenizaciÃ³n** | Divide texto en tokens |
| **Embeddings** | First guess del significado |
| **Positional Encoding** | DÃ³nde estÃ¡ cada token |
| **Attention** | QuÃ© tokens impactan a cuÃ¡les |
| **Feedforward** | Refina entendimiento con contexto |
| **Layers** | Repite attention+feedforward 8-64x |
| **Generation** | Predice y elige siguiente token |

---

## Key Takeaways:

```
1. RAG funciona porque attention entiende relaciones profundas

2. LLMs son ALEATORIOS - pueden ignorar el contexto

3. LLMs son COSTOSOS - costo crece con longitud

4. Cada token generado requiere procesar TODO el prompt
```

---

## PrÃ³ximo: Construyendo Llamadas a LLM en CÃ³digo

CÃ³mo interactuar con LLMs programÃ¡ticamente.

---
