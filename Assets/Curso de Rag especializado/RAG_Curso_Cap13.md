# Cap√≠tulo 13: Semantic Search

---

## ¬øQu√© es Semantic Search?

> "Semantic search puede matchear documentos a prompts bas√°ndose en **significado compartido**, capturando matices que keyword search pierde."

### Lo que keyword search NO puede hacer:

```
‚ùå "happy" vs "glad" ‚Üí Son sin√≥nimos, pero NO matchean
‚ùå "Python" (lenguaje) vs "Python" (serpiente) ‚Üí Matchean incorrectamente
```

### Lo que semantic search S√ç puede hacer:

```
‚úÖ "happy" ‚âà "glad" ‚Üí Entiende que son sin√≥nimos
‚úÖ "Python programming" ‚â† "python snake" ‚Üí Entiende el contexto
```

---

## Alto Nivel: Igual que Keyword Search

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                         ‚îÇ
‚îÇ   KEYWORD SEARCH:                                      ‚îÇ
‚îÇ   Documento ‚Üí Vector (conteo de palabras)              ‚îÇ
‚îÇ   Prompt ‚Üí Vector (conteo de palabras)                 ‚îÇ
‚îÇ   Comparar vectores ‚Üí Score ‚Üí Ranking                  ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   SEMANTIC SEARCH:                                     ‚îÇ
‚îÇ   Documento ‚Üí Vector (embedding)                       ‚îÇ
‚îÇ   Prompt ‚Üí Vector (embedding)                          ‚îÇ
‚îÇ   Comparar vectores ‚Üí Score ‚Üí Ranking                  ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   La diferencia est√° en C√ìMO se generan los vectores   ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Embedding Models: La Magia

### ¬øQu√© hace un embedding model?

```
EMBEDDING MODEL = Modelo matem√°tico que mapea 
                  palabras/frases/documentos 
                  a UBICACIONES EN EL ESPACIO
```

### Ejemplo simple (2D):

```
"pizza" ‚Üí vector [3, 1]
"bear" ‚Üí vector [5, 2]

En un plano X-Y:

  Y
  ‚îÇ
  ‚îÇ     ‚Ä¢ bear (5,2)
  ‚îÇ   ‚Ä¢ pizza (3,1)
  ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ X
```

---

## La Parte M√°gica

> "El embedding model mapea palabras sem√°nticamente similares a ubicaciones CERCANAS en el espacio."

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                         ‚îÇ
‚îÇ   ESPACIO DE EMBEDDINGS (2D simplificado):             ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ         ‚Ä¢ trombone                                     ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ                              ‚Ä¢ cat                     ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   ‚Ä¢ food                                               ‚îÇ
‚îÇ     ‚Ä¢ cuisine   ‚Üê CERCANOS (significado similar)      ‚îÇ
‚îÇ       ‚Ä¢ pizza                                          ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   Palabras similares = Ubicaciones cercanas            ‚îÇ
‚îÇ   Palabras diferentes = Ubicaciones lejanas            ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### No hay "ejes" interpretables:

```
No existe un "eje de comida" o "eje de animales".
Son dimensiones abstractas que el modelo aprendi√≥.

Solo pens√° en puntos flotando en el espacio,
con conceptos similares agrupados juntos.
```

---

## Dimensiones Reales

### ¬øPor qu√© m√°s dimensiones?

```
2D: Muy limitado para capturar relaciones complejas
3D: Un poco mejor, m√°s espacio para clusters

REALIDAD: 
‚îú‚îÄ‚îÄ Cientos a MILES de dimensiones
‚îú‚îÄ‚îÄ T√≠pico: 384, 768, 1024, 1536 dimensiones
‚îî‚îÄ‚îÄ Enorme flexibilidad para ubicar conceptos
```

### Imposible de visualizar, pero matem√°ticamente igual:

```
Vector 2D: [3, 1]
Vector 768D: [0.23, -0.87, 0.12, 0.45, ..., 0.33]  (768 n√∫meros)

Mismos principios:
‚îú‚îÄ‚îÄ Vectores cercanos = conceptos similares
‚îî‚îÄ‚îÄ Vectores lejanos = conceptos diferentes
```

---

## Embeddings de Diferentes Tama√±os

### No solo palabras:

| Input | Output |
|-------|--------|
| **Palabra** | Un vector |
| **Oraci√≥n** | Un vector |
| **Documento completo** | Un vector |

### Ejemplo con oraciones:

```
Oraci√≥n 1: "He spoke softly in class"
Oraci√≥n 2: "He whispered quietly during class"
Oraci√≥n 3: "Her daughter brightened the gloomy day"

En el espacio de embeddings:

        ‚Ä¢ Oraci√≥n 3 (tema diferente, lejos)



   ‚Ä¢ Oraci√≥n 1  ‚Ä¢ Oraci√≥n 2  (significado similar, cerca)
```

---

## Midiendo Distancia Entre Vectores

### 3 m√©todos comunes:

| M√©todo | Qu√© mide | Rango |
|--------|----------|-------|
| **Euclidean Distance** | Distancia en l√≠nea recta | 0 ‚Üí ‚àû |
| **Cosine Similarity** | Similitud de direcci√≥n | -1 ‚Üí 1 |
| **Dot Product** | Proyecci√≥n de un vector en otro | -‚àû ‚Üí ‚àû |

---

### 1. Euclidean Distance (Distancia Euclidiana)

```
La l√≠nea recta m√°s corta entre dos puntos.
(Teorema de Pit√°goras en N dimensiones)

        ‚Ä¢ B
       /|
      / |
     /  |
    ‚Ä¢‚îÄ‚îÄ‚îÄ‚îò
    A

Distancia = ‚àö[(x‚ÇÇ-x‚ÇÅ)¬≤ + (y‚ÇÇ-y‚ÇÅ)¬≤ + ...]

Problema: En dimensiones altas, TODO est√° lejos de TODO.
```

---

### 2. Cosine Similarity (M√°s usado)

```
Mide si dos vectores APUNTAN en la misma direcci√≥n,
sin importar qu√© tan lejos est√©n.

Ejemplo:
Vector [10, 10] y Vector [100, 100]
‚îú‚îÄ‚îÄ Est√°n lejos en el espacio
‚îî‚îÄ‚îÄ PERO apuntan en la misma direcci√≥n
    ‚Üí Cosine similarity ‚âà 1

Rango:
‚îú‚îÄ‚îÄ 1 = misma direcci√≥n (muy similares)
‚îú‚îÄ‚îÄ 0 = perpendiculares (sin relaci√≥n)
‚îî‚îÄ‚îÄ -1 = direcciones opuestas (opuestos)
```

---

### 3. Dot Product (Producto Punto)

```
Combina direcci√≥n Y longitud de los vectores.

‚îú‚îÄ‚îÄ Misma direcci√≥n y largos = valor alto positivo
‚îú‚îÄ‚îÄ Perpendiculares (90¬∞) = 0
‚îî‚îÄ‚îÄ Direcciones opuestas = valor negativo

Rango: -‚àû a +‚àû
```

---

### Resumen de m√©tricas:

```
Para AMBOS cosine similarity y dot product:
‚îú‚îÄ‚îÄ Valores M√ÅS ALTOS = vectores m√°s CERCANOS
‚îî‚îÄ‚îÄ Vectores m√°s cercanos = conceptos m√°s SIMILARES
```

---

## El Proceso de Semantic Search

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                         ‚îÇ
‚îÇ   1. PRE-PROCESO (una sola vez):                       ‚îÇ
‚îÇ      Todos los documentos ‚Üí Embedding Model ‚Üí Vectores ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ      Doc A ‚Üí [0.2, -0.5, 0.8, ...]                     ‚îÇ
‚îÇ      Doc B ‚Üí [0.1, 0.3, -0.2, ...]                     ‚îÇ
‚îÇ      Doc C ‚Üí [0.9, -0.1, 0.4, ...]                     ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   2. EN CADA B√öSQUEDA:                                 ‚îÇ
‚îÇ      Prompt ‚Üí Embedding Model ‚Üí Vector del prompt      ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ      "¬øC√≥mo hacer pizza?" ‚Üí [0.3, -0.4, 0.7, ...]     ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   3. COMPARAR:                                         ‚îÇ
‚îÇ      Medir distancia entre vector del prompt           ‚îÇ
‚îÇ      y vector de CADA documento                        ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   4. RANKEAR:                                          ‚îÇ
‚îÇ      Ordenar documentos por distancia                  ‚îÇ
‚îÇ      (m√°s cercano = m√°s similar = mejor match)         ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   5. RETORNAR:                                         ‚îÇ
‚îÇ      Los documentos m√°s cercanos al prompt             ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Por Qu√© Funciona

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                         ‚îÇ
‚îÇ   El embedding model fue ENTRENADO para que:           ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   ‚Ä¢ Conceptos similares ‚Üí ubicaciones cercanas         ‚îÇ
‚îÇ   ‚Ä¢ Conceptos diferentes ‚Üí ubicaciones lejanas         ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   Entonces:                                            ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   ‚Ä¢ Prompt cercano a documento = significado similar   ‚îÇ
‚îÇ   ‚Ä¢ Distancia cuantifica relevancia                    ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Aplicaci√≥n para DONA üéØ

### Casos donde semantic search brilla:

```
Query: "algo para pegar ladrillos"
       ‚Üì embedding
       [0.3, 0.7, -0.2, ...]
       
Documento: "Mortero de alba√±iler√≠a para muros"
           ‚Üì embedding
           [0.35, 0.68, -0.18, ...]  ‚Üê MUY CERCANO

Keyword search: ‚ùå (no comparte palabras)
Semantic search: ‚úÖ (significado similar)
```

### M√°s ejemplos para DONA:

| Query del usuario | Documento en cat√°logo | Keyword | Semantic |
|-------------------|----------------------|---------|----------|
| "fierro" | "Hierro del 8" | ‚ùå | ‚úÖ |
| "cemento gris com√∫n" | "Cemento Portland Normal" | ‚ùå | ‚úÖ |
| "material para techo" | "Chapa galvanizada" | ‚ùå | ‚úÖ |
| "pegamento para cer√°mica" | "Adhesivo para revestimientos" | ‚ùå | ‚úÖ |

---

## Resumen del Cap√≠tulo 13

| Concepto | Explicaci√≥n |
|----------|-------------|
| **Semantic Search** | Busca por SIGNIFICADO, no palabras exactas |
| **Embedding Model** | Mapea texto a vectores en espacio N-dimensional |
| **Vectores cercanos** | Significados similares |
| **Cosine Similarity** | M√©todo m√°s com√∫n para medir cercan√≠a |
| **Ventaja** | Entiende sin√≥nimos y contexto |

---

## Key Takeaway:

> "Semantic search funciona porque el embedding model fue entrenado para poner conceptos similares cerca en el espacio. La distancia entre vectores cuantifica la relevancia."

---

## Pr√≥ximo: C√≥mo se Entrenan los Embedding Models

Deep dive en c√≥mo estos modelos "aprenden" a ubicar conceptos similares juntos.

---
