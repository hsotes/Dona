# Cap√≠tulo 29: Controlando la Aleatoriedad del LLM

---

## La Realidad de los LLMs

> "Una gran parte de trabajar con un LLM es entender y controlar la aleatoriedad en el coraz√≥n de c√≥mo operan."

```
Cada token que un LLM agrega a tu completion
es una ELECCI√ìN ALEATORIA PONDERADA.
```

---

## Distribuci√≥n de Probabilidades

### Ejemplo: "The sky is ___"

```
Probabilidades del siguiente token:

blue     ‚Üí 50%
bright   ‚Üí 25%
clear    ‚Üí 10%
...
other    ‚Üí <1%
```

### Visualizaci√≥n:

```
DISTRIBUCI√ìN "CONFIDENT" (spike alto):
‚îÇ
‚îÇ  ‚ñì
‚îÇ  ‚ñì
‚îÇ  ‚ñì ‚ñì
‚îÇ  ‚ñì ‚ñì ‚ñë
‚îÇ  ‚ñì ‚ñì ‚ñë ‚ñë ‚ñë ‚ñë ‚ñë ‚ñë ‚ñë ‚ñë ‚ñë
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  blue bright clear ...

El modelo est√° SEGURO - pocas opciones reales.


DISTRIBUCI√ìN "UNCERTAIN" (m√°s plana):
‚îÇ
‚îÇ  ‚ñì ‚ñì ‚ñì ‚ñì
‚îÇ  ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì
‚îÇ  ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñë
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  many tokens with similar probabilities

El modelo est√° INCIERTO - muchas direcciones posibles.
```

---

## T√©cnica 1: Greedy Decoding

### La idea:

```
SIEMPRE elegir el token con la probabilidad m√°s alta.
Sin aleatoriedad.
```

### Ventajas:

```
‚úÖ DETERMIN√çSTICO
   Mismo prompt ‚Üí siempre misma respuesta

‚úÖ √ötil para debugging
   Pod√©s reproducir exactamente el mismo output
```

### Desventajas:

```
‚ùå Texto PREDECIBLE y gen√©rico
   Puede sonar rob√≥tico o estilizado

‚ùå LOOPS REPETITIVOS
   El LLM puede quedarse repitiendo la misma secuencia
   
   "The best way to do this is to do this is to do this is..."
   
   No hay mecanismo para salir del loop.
```

### Cu√°ndo usar:

```
‚îú‚îÄ‚îÄ Code completion (quer√©s predictibilidad)
‚îú‚îÄ‚îÄ Debugging (quer√©s reproducibilidad)
‚îî‚îÄ‚îÄ Respuestas factuales cortas
```

---

## T√©cnica 2: Temperature

### La idea:

```
Un "dial" que cambia la FORMA de la distribuci√≥n de probabilidades.
```

### Valores:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                         ‚îÇ
‚îÇ   TEMPERATURE = 1.0 (default)                          ‚îÇ
‚îÇ   Distribuci√≥n original, sin modificar.                ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   TEMPERATURE < 1.0 (ej: 0.7)                          ‚îÇ
‚îÇ   Distribuci√≥n m√°s "SPIKY"                             ‚îÇ
‚îÇ   Solo tokens m√°s probables tienen chance real          ‚îÇ
‚îÇ   ‚Üí M√°s conservador, m√°s predecible                    ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   TEMPERATURE = 0                                      ‚îÇ
‚îÇ   = Greedy decoding                                    ‚îÇ
‚îÇ   Solo el token m√°s probable (100%)                    ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   TEMPERATURE > 1.0 (ej: 1.2)                          ‚îÇ
‚îÇ   Distribuci√≥n m√°s "FLAT"                              ‚îÇ
‚îÇ   Tokens menos probables tienen m√°s chance              ‚îÇ
‚îÇ   ‚Üí M√°s variado, m√°s "creativo"                        ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ   TEMPERATURE muy alta (ej: 2.0)                       ‚îÇ
‚îÇ   Distribuci√≥n MUY flat                                ‚îÇ
‚îÇ   Casi cualquier token tiene chance similar            ‚îÇ
‚îÇ   ‚Üí CAOS, texto sin sentido                            ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Visualizaci√≥n:

```
Temperature 0.5 (bajo):           Temperature 1.5 (alto):
‚îÇ                                 ‚îÇ
‚îÇ  ‚ñì                              ‚îÇ  ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì
‚îÇ  ‚ñì                              ‚îÇ  ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì
‚îÇ  ‚ñì ‚ñë                            ‚îÇ  ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì
‚îÇ  ‚ñì ‚ñë ‚ñë ‚ñë ‚ñë ‚ñë ‚ñë ‚ñë                ‚îÇ  ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì ‚ñì
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

Casi seguro elige "blue"          Muchas opciones viables
```

---

## T√©cnica 3: Top-K Sampling

### La idea:

```
Limitar al LLM a elegir SOLO de los K tokens m√°s probables.
```

### Ejemplo:

```
Top K = 5

Tokens disponibles:
1. blue    (50%)
2. bright  (25%)
3. clear   (10%)
4. dark    (8%)
5. endless (5%)

Todos los dem√°s tokens ‚Üí probabilidad 0
(no importa cu√°ntos hab√≠a originalmente)
```

### Uso:

```python
response = llm.generate(
    prompt="The sky is",
    temperature=1.1,
    top_k=5  # Solo los 5 m√°s probables
)
```

---

## T√©cnica 4: Top-P Sampling (Nucleus Sampling)

### La idea:

```
Limitar al LLM a tokens cuya probabilidad ACUMULADA
sea menor que un threshold P.
```

### Ejemplo:

```
Top P = 0.85 (85%)

Acumulando desde el m√°s probable:
1. blue    (50%)  ‚Üí acumulado: 50%  ‚úÖ incluido
2. bright  (25%)  ‚Üí acumulado: 75%  ‚úÖ incluido
3. clear   (10%)  ‚Üí acumulado: 85%  ‚úÖ incluido
4. dark    (8%)   ‚Üí acumulado: 93%  ‚ùå excede 85%

Solo tokens 1-3 est√°n disponibles.
```

### Top-K vs Top-P:

```
TOP-K: Siempre elige de K tokens (fijo)
       No importa la forma de la distribuci√≥n.

TOP-P: Elige de m√°s/menos tokens seg√∫n la confianza
       - Si el modelo est√° seguro ‚Üí pocos tokens
       - Si est√° incierto ‚Üí m√°s tokens

TOP-P es m√°s DIN√ÅMICO y RESPONSIVO.
```

---

## T√©cnica 5: Repetition Penalty

### El problema:

```
Los LLMs tienden a repetir palabras o frases:

"This is a great product. This product is great. 
 The product is really great and this great product..."
```

### La soluci√≥n:

```
Repetition Penalty DISMINUYE la probabilidad de
tokens que ya aparecieron en el completion.

repetition_penalty = 1.2

Si "great" ya apareci√≥, su probabilidad baja
para el siguiente token.
```

---

## T√©cnica 6: Logit Biasing

### La idea:

```
Ajustar PERMANENTEMENTE la probabilidad de tokens espec√≠ficos.
```

### Ejemplos de uso:

```
1. EVITAR PROFANIDAD:
   Bias negativo en palabras que no quer√©s que aparezcan.

2. CLASIFICACI√ìN:
   Si el LLM debe responder solo "positive" o "negative",
   boost la probabilidad de esos tokens espec√≠ficos.

3. FORZAR FORMATO:
   Boost tokens como "{" o "[" para forzar JSON.
```

---

## Configuraci√≥n Recomendada

### Para uso general:

```python
response = llm.generate(
    prompt=augmented_prompt,
    temperature=0.8,       # Un poco conservador
    top_p=0.9,             # Evita la cola larga
    repetition_penalty=1.2 # Penaliza repetici√≥n
)
```

### Por tipo de tarea:

| Tarea | Temperature | Top-P | Notas |
|-------|-------------|-------|-------|
| **C√≥digo** | 0.2-0.5 | 0.8 | Quer√©s predictibilidad |
| **Preguntas factuales** | 0.3-0.7 | 0.85 | Basarse en hechos |
| **RAG general** | 0.7-0.9 | 0.9 | Balance |
| **Escritura creativa** | 1.0-1.3 | 0.95 | M√°s variedad |
| **Brainstorming** | 1.2-1.5 | 0.95 | Exploraci√≥n |

---

## Aplicaci√≥n para DONA üéØ

### Configuraci√≥n recomendada para DONA:

```python
dona_llm_config = {
    "temperature": 0.7,      # Respuestas consistentes pero naturales
    "top_p": 0.9,            # Evitar tokens raros
    "repetition_penalty": 1.1,  # Evitar repetir precios/productos
    "max_tokens": 500        # Respuestas concisas
}
```

### Por qu√© estos valores:

```
TEMPERATURE 0.7:
‚îú‚îÄ‚îÄ No queremos que invente precios (bajo)
‚îú‚îÄ‚îÄ Pero queremos respuestas naturales (no 0)
‚îî‚îÄ‚îÄ Balance entre factual y conversacional

TOP-P 0.9:
‚îú‚îÄ‚îÄ Evita tokens nonsense
‚îú‚îÄ‚îÄ Pero permite variaci√≥n en lenguaje
‚îî‚îÄ‚îÄ No tan restrictivo como 0.8

REPETITION PENALTY 1.1:
‚îú‚îÄ‚îÄ Evita repetir "el precio es" m√∫ltiples veces
‚îú‚îÄ‚îÄ Pero no tan alto que suene forzado
‚îî‚îÄ‚îÄ Mantiene naturalidad
```

### Escenarios espec√≠ficos de DONA:

```
CONSULTA DE PRECIO:
temperature=0.5, top_p=0.85
‚Üí Queremos respuesta factual y consistente

RECOMENDACI√ìN DE PRODUCTO:
temperature=0.8, top_p=0.9
‚Üí Queremos respuesta m√°s exploratoria

EXPLICACI√ìN T√âCNICA:
temperature=0.6, top_p=0.9
‚Üí Factual pero con espacio para variaci√≥n
```

---

## Resumen del Cap√≠tulo 29

| T√©cnica | Qu√© controla | Valor t√≠pico |
|---------|--------------|--------------|
| **Greedy** | Sin aleatoriedad | temp=0 |
| **Temperature** | Forma de distribuci√≥n | 0.7-1.0 |
| **Top-K** | Cantidad fija de opciones | 5-50 |
| **Top-P** | Opciones seg√∫n confianza | 0.85-0.95 |
| **Repetition Penalty** | Penaliza repetici√≥n | 1.1-1.3 |
| **Logit Bias** | Tokens espec√≠ficos | Variable |

---

## Key Takeaway:

> "En general, recomiendo configurar temperature y top_p que mejor se ajusten a tus necesidades. Para c√≥digo o preguntas factuales, valores bajos. Para dominios creativos, valores m√°s altos."

---

## Pr√≥ximo: Prompting para RAG

C√≥mo estructurar prompts para obtener respuestas grounded.

---
