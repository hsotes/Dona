# CapÃ­tulo 26: Wrap-up MÃ³dulo 3 - Vector Databases

---

## Resumen del MÃ³dulo

> "Â¡Felicitaciones! Ahora tenÃ©s todas las habilidades necesarias para configurar un retriever muy capaz."

---

## Lo Que Aprendiste

### 1. Approximate Nearest Neighbors (ANN)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   ANN realiza vector search SIGNIFICATIVAMENTE         â”‚
â”‚   mÃ¡s rÃ¡pido que KNN brute-force.                      â”‚
â”‚                                                         â”‚
â”‚   Trade-off: Potencialmente no encuentra los           â”‚
â”‚   documentos ABSOLUTOS mejores, pero encuentra         â”‚
â”‚   documentos MUY cercanos.                             â”‚
â”‚                                                         â”‚
â”‚   HNSW: O(log n) vs KNN: O(n)                         â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Vector Databases

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   Optimizadas para:                                    â”‚
â”‚   â”œâ”€â”€ Almacenar datos vectoriales de alta dimensiÃ³n   â”‚
â”‚   â”œâ”€â”€ Realizar bÃºsquedas ANN                          â”‚
â”‚   â””â”€â”€ Escalar sistemas RAG                            â”‚
â”‚                                                         â”‚
â”‚   La base de datos GO-TO para RAG a escala.           â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Chunking

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   Dividir documentos en pedazos mÃ¡s pequeÃ±os:          â”‚
â”‚                                                         â”‚
â”‚   âœ… Vectores capturan significado mÃ¡s precisamente    â”‚
â”‚   âœ… Usa menos espacio en el context window del LLM    â”‚
â”‚                                                         â”‚
â”‚   TÃ©cnicas:                                            â”‚
â”‚   â”œâ”€â”€ Fixed size + overlap (default)                  â”‚
â”‚   â”œâ”€â”€ Recursive character splitting                    â”‚
â”‚   â”œâ”€â”€ Semantic chunking                                â”‚
â”‚   â””â”€â”€ Context-aware chunking                           â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Query Parsing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   Mejorar prompts del usuario para optimizar retrieval:â”‚
â”‚                                                         â”‚
â”‚   TÃ©cnicas:                                            â”‚
â”‚   â”œâ”€â”€ Query Rewriting (LLM) â† SIEMPRE usar            â”‚
â”‚   â”œâ”€â”€ Named Entity Recognition (NER)                   â”‚
â”‚   â””â”€â”€ HyDE (Hypothetical Document Embeddings)          â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. Re-ranking

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   Usar arquitecturas de alta capacidad para identificarâ”‚
â”‚   mejor los documentos relevantes entre los que        â”‚
â”‚   la Vector DB recuperÃ³ con hybrid search.             â”‚
â”‚                                                         â”‚
â”‚   Flujo: Over-fetch (20-25) â†’ Re-rank â†’ Return (5-10) â”‚
â”‚                                                         â”‚
â”‚   Modelos: Cross-encoder, LLM-based                    â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Resumen de CapÃ­tulos del MÃ³dulo 3

| Cap | Tema | Key Takeaway |
|-----|------|--------------|
| 18 | Overview | Vector DBs son esenciales para RAG a escala |
| 19 | Algoritmos | HNSW: O(log n), aproximado pero muy rÃ¡pido |
| 20 | Weaviate | Hybrid search con alpha, filters |
| 21 | Chunking bÃ¡sico | Fixed size ~500 chars, 10% overlap |
| 22 | Chunking avanzado | Semantic, LLM-based, context-aware |
| 23 | Query Parsing | Query rewriting es esencial |
| 24 | Arquitecturas | Bi-encoder (default), Cross-encoder (re-rank), ColBERT |
| 25 | Re-ranking | Over-fetch â†’ Cross-encoder â†’ Top K |
| 26 | Wrap-up | Todo junto |

---

## TÃ©cnicas: Standard vs Avanzadas

| Ãrea | Standard (usar primero) | Avanzado (si es necesario) |
|------|------------------------|---------------------------|
| **Chunking** | Fixed size + overlap | Semantic, LLM-based |
| **Query Parsing** | Query rewriting | NER, HyDE |
| **Search** | Hybrid (keyword + semantic) | ColBERT |
| **Re-ranking** | Cross-encoder | LLM-based |

---

## El Pipeline Completo de Retrieval

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚   PRE-PROCESO (una vez):                               â”‚
â”‚   Documentos â†’ Chunking â†’ Embeddings â†’ Vector DB       â”‚
â”‚                                                         â”‚
â”‚   POR CADA QUERY:                                      â”‚
â”‚                                                         â”‚
â”‚   1. Usuario envÃ­a mensaje                             â”‚
â”‚      "Che, cuÃ¡nto sale el fierro del 8?"               â”‚
â”‚                                                         â”‚
â”‚   2. Query Parsing                                     â”‚
â”‚      â†’ "Precio hierro/varilla 8mm"                     â”‚
â”‚                                                         â”‚
â”‚   3. Hybrid Search (over-fetch)                        â”‚
â”‚      â†’ 20-25 documentos                                â”‚
â”‚                                                         â”‚
â”‚   4. Metadata Filtering                                â”‚
â”‚      â†’ Filtrar por categoria, disponibilidad           â”‚
â”‚                                                         â”‚
â”‚   5. Re-ranking                                        â”‚
â”‚      â†’ Top 5-10 documentos mÃ¡s relevantes              â”‚
â”‚                                                         â”‚
â”‚   6. â†’ LLM para generar respuesta                      â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## AplicaciÃ³n para DONA ğŸ¯

### Checklist de implementaciÃ³n:

```
VECTOR DATABASE:
â–¡ Weaviate/Pinecone/similar configurado
â–¡ Collection con schema correcto
â–¡ Metadata: categoria, marca, codigo, disponibilidad

CHUNKING:
â–¡ Productos: probablemente no necesitan chunking
â–¡ Manuales: fixed size o por secciones
â–¡ Metadata heredada en cada chunk

QUERY PARSING:
â–¡ Query rewriter configurado
â–¡ Limpia lenguaje coloquial
â–¡ Extrae producto, medida, marca

HYBRID SEARCH:
â–¡ Alpha balanceado (0.5 para empezar)
â–¡ Metadata filters activos
â–¡ Over-fetch configurado (20-25)

RE-RANKING:
â–¡ Cross-encoder habilitado
â–¡ Retorna top 5-10
```

### ConfiguraciÃ³n recomendada para DONA:

```python
dona_retriever_config = {
    # Chunking
    "chunk_size": 300,
    "chunk_overlap": 50,
    
    # Hybrid Search
    "alpha": 0.5,
    "over_fetch": 20,
    "final_limit": 5,
    
    # Metadata
    "filters": ["categoria", "disponibilidad"],
    
    # Re-ranking
    "reranker": "cross-encoder",
    
    # Query Parsing
    "query_rewriter": True
}
```

---

## Key Takeaways del MÃ³dulo 3

```
1. Vector DBs escalan RAG a millones/billones de docs

2. ANN (HNSW) hace posible bÃºsqueda rÃ¡pida a escala

3. Chunking mejora precisiÃ³n de vectores y uso de context window

4. Query rewriting es ESENCIAL (casi siempre)

5. Re-ranking es una de las PRIMERAS mejoras a implementar

6. Empezar con tÃ©cnicas standard, avanzar si es necesario
```

---

# Fin del MÃ³dulo 3: Vector Databases âœ…

## PrÃ³ximo: MÃ³dulo 4 - LLMs para RAG

CÃ³mo obtener el mÃ¡ximo del LLM que procesa los documentos recuperados y genera la respuesta.

---
